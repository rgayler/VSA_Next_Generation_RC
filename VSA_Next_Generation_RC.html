<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.340">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Ross Gayler">
<meta name="dcterms.date" content="2023-04-01">

<title>VSA Next Generation Reservoir Computing</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="VSA_Next_Generation_RC_files/libs/clipboard/clipboard.min.js"></script>
<script src="VSA_Next_Generation_RC_files/libs/quarto-html/quarto.js"></script>
<script src="VSA_Next_Generation_RC_files/libs/quarto-html/popper.min.js"></script>
<script src="VSA_Next_Generation_RC_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="VSA_Next_Generation_RC_files/libs/quarto-html/anchor.min.js"></script>
<link href="VSA_Next_Generation_RC_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="VSA_Next_Generation_RC_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="VSA_Next_Generation_RC_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="VSA_Next_Generation_RC_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="VSA_Next_Generation_RC_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#objectives" id="toc-objectives" class="nav-link active" data-scroll-target="#objectives"><span class="header-section-number">1</span> Objectives</a></li>
  <li><a href="#statistical-feature-construction" id="toc-statistical-feature-construction" class="nav-link" data-scroll-target="#statistical-feature-construction"><span class="header-section-number">2</span> Statistical feature construction</a>
  <ul class="collapse">
  <li><a href="#what-does-reservoir-computing-do" id="toc-what-does-reservoir-computing-do" class="nav-link" data-scroll-target="#what-does-reservoir-computing-do"><span class="header-section-number">2.1</span> What does Reservoir Computing do?</a></li>
  <li><a href="#interpretation-as-statistical-feature-construction" id="toc-interpretation-as-statistical-feature-construction" class="nav-link" data-scroll-target="#interpretation-as-statistical-feature-construction"><span class="header-section-number">2.2</span> Interpretation as statistical feature construction</a></li>
  <li><a href="#vsa-representation-of-predictors" id="toc-vsa-representation-of-predictors" class="nav-link" data-scroll-target="#vsa-representation-of-predictors"><span class="header-section-number">2.3</span> VSA representation of predictors</a></li>
  <li><a href="#theory-of-sequence-indexing" id="toc-theory-of-sequence-indexing" class="nav-link" data-scroll-target="#theory-of-sequence-indexing"><span class="header-section-number">2.4</span> Theory of sequence indexing</a></li>
  <li><a href="#integer-echo-state-network" id="toc-integer-echo-state-network" class="nav-link" data-scroll-target="#integer-echo-state-network"><span class="header-section-number">2.5</span> Integer Echo State Network</a></li>
  <li><a href="#expand-repeated-application-of-the-reservoir-update-equation" id="toc-expand-repeated-application-of-the-reservoir-update-equation" class="nav-link" data-scroll-target="#expand-repeated-application-of-the-reservoir-update-equation"><span class="header-section-number">2.6</span> Expand repeated application of the reservoir update equation</a></li>
  </ul></li>
  <li><a href="#polynomial-feature-construction" id="toc-polynomial-feature-construction" class="nav-link" data-scroll-target="#polynomial-feature-construction"><span class="header-section-number">3</span> Polynomial feature construction</a>
  <ul class="collapse">
  <li><a href="#what-does-next-generation-rc-do" id="toc-what-does-next-generation-rc-do" class="nav-link" data-scroll-target="#what-does-next-generation-rc-do"><span class="header-section-number">3.1</span> What does Next Generation RC do?</a></li>
  <li><a href="#rc-as-incremental-construction-of-predictors" id="toc-rc-as-incremental-construction-of-predictors" class="nav-link" data-scroll-target="#rc-as-incremental-construction-of-predictors"><span class="header-section-number">3.2</span> RC as incremental construction of predictors</a></li>
  </ul></li>
  <li><a href="#vsa-polynomial-reservoir-update" id="toc-vsa-polynomial-reservoir-update" class="nav-link" data-scroll-target="#vsa-polynomial-reservoir-update"><span class="header-section-number">4</span> VSA polynomial reservoir update</a>
  <ul class="collapse">
  <li><a href="#develop-polynomial-update-formulae" id="toc-develop-polynomial-update-formulae" class="nav-link" data-scroll-target="#develop-polynomial-update-formulae"><span class="header-section-number">4.1</span> Develop polynomial update formulae</a></li>
  <li><a href="#x-1n" id="toc-x-1n" class="nav-link" data-scroll-target="#x-1n"><span class="header-section-number">4.2</span> <span class="math inline">\((x + 1)^n\)</span></a></li>
  <li><a href="#multiplicative-identity-mathbf1-and-copy-arcs" id="toc-multiplicative-identity-mathbf1-and-copy-arcs" class="nav-link" data-scroll-target="#multiplicative-identity-mathbf1-and-copy-arcs"><span class="header-section-number">4.3</span> Multiplicative identity (<span class="math inline">\(\mathbf{1}\)</span>) and copy arcs</a></li>
  <li><a href="#reservoir-update-with-permutation" id="toc-reservoir-update-with-permutation" class="nav-link" data-scroll-target="#reservoir-update-with-permutation"><span class="header-section-number">4.4</span> Reservoir update with permutation</a></li>
  </ul></li>
  <li><a href="#feature-fading" id="toc-feature-fading" class="nav-link" data-scroll-target="#feature-fading"><span class="header-section-number">5</span> Feature fading</a>
  <ul class="collapse">
  <li><a href="#nonassociative-bundling" id="toc-nonassociative-bundling" class="nav-link" data-scroll-target="#nonassociative-bundling"><span class="header-section-number">5.1</span> Nonassociative bundling</a></li>
  <li><a href="#weighted-bundling" id="toc-weighted-bundling" class="nav-link" data-scroll-target="#weighted-bundling"><span class="header-section-number">5.2</span> Weighted bundling</a></li>
  <li><a href="#bundled-inputs" id="toc-bundled-inputs" class="nav-link" data-scroll-target="#bundled-inputs"><span class="header-section-number">5.3</span> Bundled inputs</a></li>
  </ul></li>
  <li><a href="#development-suggestions" id="toc-development-suggestions" class="nav-link" data-scroll-target="#development-suggestions"><span class="header-section-number">6</span> Development suggestions</a>
  <ul class="collapse">
  <li><a href="#inputhierarchical-encoding" id="toc-inputhierarchical-encoding" class="nav-link" data-scroll-target="#inputhierarchical-encoding"><span class="header-section-number">6.1</span> Input/hierarchical encoding</a></li>
  <li><a href="#intercept-term" id="toc-intercept-term" class="nav-link" data-scroll-target="#intercept-term"><span class="header-section-number">6.2</span> Intercept term</a></li>
  <li><a href="#bundling-and-capacity" id="toc-bundling-and-capacity" class="nav-link" data-scroll-target="#bundling-and-capacity"><span class="header-section-number">6.3</span> Bundling and capacity</a></li>
  <li><a href="#warm-up" id="toc-warm-up" class="nav-link" data-scroll-target="#warm-up"><span class="header-section-number">6.4</span> Warm up</a></li>
  <li><a href="#dynamic-readout" id="toc-dynamic-readout" class="nav-link" data-scroll-target="#dynamic-readout"><span class="header-section-number">6.5</span> Dynamic readout</a></li>
  <li><a href="#dynamic-update" id="toc-dynamic-update" class="nav-link" data-scroll-target="#dynamic-update"><span class="header-section-number">6.6</span> Dynamic update</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="header-section-number">7</span> References</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="VSA_Next_Generation_RC.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li></ul></div></nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">VSA Next Generation Reservoir Computing</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Ross Gayler </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">April 1, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<div style="page-break-after: always;"></div>
<section id="objectives" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Objectives</h1>
<p>The aim of this project is to develop good VSA implementations of Next Generation Reservoir Computing <span class="citation" data-cites="gauthierNextGenerationReservoir2021">(<a href="#ref-gauthierNextGenerationReservoir2021" role="doc-biblioref">Gauthier et al. 2021</a>)</span>. The sought outcomes are:</p>
<ul>
<li><p>A good, practical multivariate dynamical system predictor;</p></li>
<li><p>Further theoretical development of VSA through exposure of current understanding to new practical problems. (I view theoretical development as being about finding productive interpretations/extensions of the abstract basis of VSA.)</p></li>
</ul>
<div style="page-break-after: always;"></div>
</section>
<section id="statistical-feature-construction" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Statistical feature construction</h1>
<section id="what-does-reservoir-computing-do" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="what-does-reservoir-computing-do"><span class="header-section-number">2.1</span> What does Reservoir Computing do?</h2>
<p>Reservoir computing uses a recurrently updated reservoir to create a representation vector from a sequence of input values. The reservoir value is transformed to predictions by a simple linear readout transformation, for example see <span class="citation" data-cites="gauthierNextGenerationReservoir2021">(<a href="#ref-gauthierNextGenerationReservoir2021" role="doc-biblioref">Gauthier et al. 2021, fig. 1</a>)</span>.</p>
</section>
<section id="interpretation-as-statistical-feature-construction" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="interpretation-as-statistical-feature-construction"><span class="header-section-number">2.2</span> Interpretation as statistical feature construction</h2>
<p>The linear readout is equivalent to the application of a standard statistical regression model. A standard univariate regression model is effectively the calculation of the dot product of the vector of regression coefficients and the vector of predictor values. A multivariate regression is the concatenation of multiple univariate regressions (so the vector of regression coefficients becomes a matrix of regression coefficients). Under this interpretation, the reservoir is constructing the vector of predictor values to be input to the regression model.</p>
</section>
<section id="vsa-representation-of-predictors" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="vsa-representation-of-predictors"><span class="header-section-number">2.3</span> VSA representation of predictors</h2>
<p>In standard statistics/ML the representation of predictor values is localist. However, in VSA the natural form of representation is distributed key-value pairs, with the key corresponding to the identity of the predictor and the value corresponding to the value of the predictor <span class="citation" data-cites="kanervaFullyDistributedRepresentation1997">(<a href="#ref-kanervaFullyDistributedRepresentation1997" role="doc-biblioref">Kanerva 1997</a>)</span>. I <em>think</em> that the distributed representations can be viewed as rotations of a localist representation <span class="citation" data-cites="qiuGraphEmbeddingsTensor2022">(<a href="#ref-qiuGraphEmbeddingsTensor2022" role="doc-biblioref">Qiu, n.d., sec. 6.1</a>)</span>.</p>
<p>It’s also worth noting that in standard statistics/ML the value of a predictor is represented as the scalar value of the predictor variable. This can be directly implemented by representing the value of the predictor variable by the magnitude of the hypervector (e.g. <span class="citation" data-cites="kleykoIntegerEchoState2022">Kleyko, Frady, et al. (<a href="#ref-kleykoIntegerEchoState2022" role="doc-biblioref">2022</a>)</span>, sec IV.A.2). Note that this represents the predictor as a key rather than a key-value pair. An alternative is to represent the value of a predictor by the direction of a hypervector (e.g.&nbsp;by Fractional Power Encoding).</p>
</section>
<section id="theory-of-sequence-indexing" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="theory-of-sequence-indexing"><span class="header-section-number">2.4</span> Theory of sequence indexing</h2>
<p>The theory of sequence indexing and working memory in recurrent neural networks <span class="citation" data-cites="fradyTheorySequenceIndexing2018a">(<a href="#ref-fradyTheorySequenceIndexing2018a" role="doc-biblioref">Frady, Kleyko, and Sommer 2018</a>)</span> appears to be very relevant to this project, but I haven’t read it in detail yet. On the basis of a quick skim this project appears to differ by stressing the algebraic interpretation of the action of the reservoir update. In this project we interpret the reservoir update as algebraic VSA operations.</p>
</section>
<section id="integer-echo-state-network" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="integer-echo-state-network"><span class="header-section-number">2.5</span> Integer Echo State Network</h2>
<p>We’ll start by applying this lens (algebraic interpretation of the reservoir update) to the Integer Echo State Network. The reservoir update equation <span class="citation" data-cites="kleykoIntegerEchoState2022">(<a href="#ref-kleykoIntegerEchoState2022" role="doc-biblioref">Kleyko, Frady, et al. 2022</a>, eqn. 5)</span> is: <span class="math display">\[\mathbf{x}(n) = f_\kappa(Sh(\mathbf{x}(n-1), 1) + \mathbf{u}^{\textrm{HD}}(n) + \mathbf{y}^{\textrm{HD}}(n-1))\]</span> where <span class="math inline">\(\mathbf{x}(n)\)</span> is the value of the hypervector representing the state of the reservoir at time <span class="math inline">\(n\)</span>; <span class="math inline">\(f_\kappa()\)</span> is the clipping function applied to the reservoir hypervector; <span class="math inline">\(Sh(\mathbf{x}(n-1), 1)\)</span> is the application of a cyclic shift (by one element) permutation to the value of the reservoir hypervector at the previous time step (<span class="math inline">\(n-1\)</span>); <span class="math inline">\(\mathbf{u}^{HD}(n)\)</span> is the hypervector encoding of the input vector at time <span class="math inline">\(n\)</span>; <span class="math inline">\(\mathbf{y}^{HD}(n-1))\)</span> is the is the hypervector encoding of the output vector at the previous time step (<span class="math inline">\(n-1\)</span>); and <span class="math inline">\(+\)</span> is hypervector addition (bundling).</p>
<p>Simplify the equation and notation a little for ease of exposition:</p>
<ul>
<li>Drop the clipping function <span class="math inline">\(f_\kappa()\)</span> (equivalent to setting the clipping threshold <span class="math inline">\(\kappa\)</span> to a high value).</li>
<li>Replace the cyclic shift function <span class="math inline">\(Sh()\)</span> with a generic, fixed permutation function <span class="math inline">\(\textrm{P}()\)</span>.</li>
<li>Drop the HD superscripts from the input and output hypervectors by interpreting <span class="math inline">\(\mathbf{u}(n)\)</span> and <span class="math inline">\(\mathbf{y}(n-1))\)</span> as the hypervector encodings of the input and output vectors at their respective time steps.</li>
<li>Drop the output hypervector <span class="math inline">\(\mathbf{y}(n-1))\)</span> because the input hypervector <span class="math inline">\(\mathbf{u}(n)\)</span> can be interpreted as including the output values.</li>
</ul>
<p>The simplified equation is: <span class="math display">\[\mathbf{x}(n) = \textrm{P}(\mathbf{x}(n-1)) + \mathbf{u}(n)\]</span></p>
</section>
<section id="expand-repeated-application-of-the-reservoir-update-equation" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="expand-repeated-application-of-the-reservoir-update-equation"><span class="header-section-number">2.6</span> Expand repeated application of the reservoir update equation</h2>
<p>Trace out the repeated application, starting from time <span class="math inline">\(n = 0\)</span> with an empty reservoir, <span class="math inline">\(\mathbf{x}(0) = \mathbf{0}\)</span>, where <span class="math inline">\(\mathbf{0}\)</span> is the additive identity hypervector.</p>
<p><span class="math inline">\(n = 0 : \mathbf{x}(0) = \mathbf{0}\)</span><br>
<br>
<span class="math inline">\(n = 1 : \mathbf{x}(1) = \textrm{P}(\mathbf{x}(0)) + \mathbf{u}(1)\)</span><br>
<span class="math inline">\(= \textrm{P}(\mathbf{0}) + \mathbf{u}(1)\)</span><br>
<span class="math inline">\(= \mathbf{0} + \mathbf{u}(1)\)</span><br>
<span class="math inline">\(= \mathbf{u}(1)\)</span><br>
<br>
<span class="math inline">\(n = 2 : \mathbf{x}(2) = \textrm{P}(\mathbf{x}(1)) + \mathbf{u}(2)\)</span><br>
<span class="math inline">\(= \textrm{P}(\mathbf{u}(1)) + \mathbf{u}(2)\)</span><br>
<br>
<span class="math inline">\(n = 3 : \mathbf{x}(3) = \textrm{P}(\mathbf{x}(2)) + \mathbf{u}(3)\)</span><br>
<span class="math inline">\(= \textrm{P}(\textrm{P}(\mathbf{u}(1)) + \mathbf{u}(2)) + \mathbf{u}(3)\)</span><br>
<span class="math inline">\(= \textrm{P}^2(\mathbf{u}(1)) + \textrm{P}(\mathbf{u}(2)) + \mathbf{u}(3)\)</span><br>
<span class="math inline">\(= \textrm{P}^2(\mathbf{u}(1)) + \textrm{P}^1(\mathbf{u}(2)) + \textrm{P}^0(\mathbf{u}(3))\)</span></p>
<p>This is a standard VSA idiom for representation of a sequence of values <span class="citation" data-cites="kleykoSurveyHyperdimensionalComputing2022a">(<a href="#ref-kleykoSurveyHyperdimensionalComputing2022a" role="doc-biblioref">Kleyko, Rachkovskij, et al. 2022</a>, eqn. 17)</span>. The representation is equivalent to a set of predictors, each of which is a lagged copy of the input values. For example, the <span class="math inline">\(\textrm{P}^2(\mathbf{u}())\)</span> term represents the value of the input two time steps earlier. All the permutations are orthogonal, so the permutations effectively constitute the identities of the predictor variables. This means that the integer Echo State Network is restricted to modelling the outputs as weighted sums of the lagged inputs.</p>
<p>A somewhat subtle point is that this reservoir update is not directly representing the sequence <span class="math inline">\(A \rightarrow B\rightarrow C\)</span> as successor relations, rather it is indicating when the states occurred (relative to the current state) and the successor relationships are implicit in the state times.</p>
<p>Note that the form of the result resembles a polynomial with the powers of the permutation corresponding to the powers of the variable of the polynomial and the input values corresponding to the coefficients of the polynomial. Note also that the result is iteratively built up, one input value at a time by transforming the result so far to reflect it’s updated role and bundling in the next input value.</p>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="polynomial-feature-construction" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Polynomial feature construction</h1>
<section id="what-does-next-generation-rc-do" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="what-does-next-generation-rc-do"><span class="header-section-number">3.1</span> What does Next Generation RC do?</h2>
<p>Next Generation Reservoir Computing replaces the recurrent reservoir calculations with the direct calculation of products of delayed input values <span class="citation" data-cites="gauthierNextGenerationReservoir2021">(<a href="#ref-gauthierNextGenerationReservoir2021" role="doc-biblioref">Gauthier et al. 2021, fig. 1</a>)</span>. This is justified by a universal approximator result showing that the NGRC is equivalent to traditional RC. The NGRC authors see the advantage of this as being the elimination of the reservoir, in particular, the random matrix implementing the reservoir update,</p>
<p>From the point of view of a statistical modeller, NGRC is constructing polynomial interaction features from the input stream to use as predictors in a simple regression model. We investigate how to create equivalent VSA polynomial interaction features using VSA mechanisms.</p>
</section>
<section id="rc-as-incremental-construction-of-predictors" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="rc-as-incremental-construction-of-predictors"><span class="header-section-number">3.2</span> RC as incremental construction of predictors</h2>
<p>We <em>could</em> create a desired set of polynomial predictors in one step, but this would require knowing which specific predictors are required and would require dedicated VSA circuitry for each predictor to be constructed. Instead, we will use a reservoir update circuit to construct <em>all</em> the polynomial predictors incrementally.</p>
<p>Note that the NGRC objection to the reservoir was actually to the random matrix. The VSA reservoir update does not use a random matrix so we don’t have the tuning problems identified by the NGRC authors.</p>
<p>VSA reservoir update relies on superposition and distributivity to construct many predictors in parallel, so it requires much less hardware than dedicated hardware for each predictor.</p>
<p>Also, note that because of the incremental update the predictor terms are constructed on a specific order. The simplest terms are constructed first and more complex terms later (with smaller magnitude). This constitutes an inductive bias to use lower order terms.</p>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="vsa-polynomial-reservoir-update" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> VSA polynomial reservoir update</h1>
<section id="develop-polynomial-update-formulae" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="develop-polynomial-update-formulae"><span class="header-section-number">4.1</span> Develop polynomial update formulae</h2>
</section>
<section id="x-1n" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="x-1n"><span class="header-section-number">4.2</span> <span class="math inline">\((x + 1)^n\)</span></h2>
<p>Base the first attempt at the reservoir update on the polynomial <span class="math inline">\((x + 1)^n\)</span>. Take the simplified update equation (where <span class="math inline">\(\times\)</span> is hypervector multiplication (binding)): <span class="math display">\[\mathbf{x}(n) = (\mathbf{x}(n-1) + \mathbf{1}) \times (\mathbf{u}(n) + \mathbf{1})\]</span></p>
<p>Trace out the repeated application of the reservoir update equation, starting from time <span class="math inline">\(n = 0\)</span> with an empty reservoir, <span class="math inline">\(\mathbf{x}(0) = \mathbf{0}\)</span>.</p>
<p><span class="math inline">\(\mathbf{x}(0) = \mathbf{0}\)</span><br>
<br>
<span class="math inline">\(\mathbf{x}(1) = (\mathbf{x}(0) + \mathbf{1}) \times (\mathbf{u}(1) + \mathbf{1})\)</span><br>
<span class="math inline">\(= (\mathbf{0} + \mathbf{1}) \times (\mathbf{u}(1) + \mathbf{1})\)</span><br>
<span class="math inline">\(= \mathbf{1} \times (\mathbf{u}(1) + \mathbf{1})\)</span><br>
<span class="math inline">\(= \mathbf{u}(1) + \mathbf{1}\)</span><br>
<br>
<span class="math inline">\(\mathbf{x}(2) = (\mathbf{x}(1) + \mathbf{1}) \times (\mathbf{u}(2) + \mathbf{1})\)</span><br>
<span class="math inline">\(= (\mathbf{u}(1) + \mathbf{1} + \mathbf{1}) \times (\mathbf{u}(2) + \mathbf{1})\)</span><br>
<span class="math inline">\(= \mathbf{u}(1) \times \mathbf{u}(2) + 2 \cdot \mathbf{u}(2) + \mathbf{u}(1) + 2\cdot \mathbf{1}\)</span><br>
<br>
<span class="math inline">\(\mathbf{x}(3) = (\mathbf{x}(2) + \mathbf{1}) \times (\mathbf{u}(3) + \mathbf{1})\)</span><br>
<span class="math inline">\(= (\mathbf{u}(1) \times \mathbf{u}(2) + 2 \cdot \mathbf{u}(2) + \mathbf{u}(1) + 2\cdot \mathbf{1} + \mathbf{1}) \times (\mathbf{u}(3) + \mathbf{1})\)</span><br>
<span class="math inline">\(= (\mathbf{u}(1) \times \mathbf{u}(2) + 2 \cdot \mathbf{u}(2) + \mathbf{u}(1) + 3\cdot \mathbf{1}) \times (\mathbf{u}(3) + \mathbf{1})\)</span><br>
<span class="math inline">\(= \mathbf{u}(1) \times \mathbf{u}(2) \times \mathbf{u}(3)+ 2 \cdot \mathbf{u}(2) \times \mathbf{u}(3) + \mathbf{u}(1) \times \mathbf{u}(3) + 3\cdot \mathbf{u}(3) + \mathbf{u}(1) \times \mathbf{u}(2) + 2 \cdot \mathbf{u}(2) + \mathbf{u}(1) + 3\cdot \mathbf{1}\)</span><br>
</p>
<p>where “<span class="math inline">\(\cdot\)</span>” is for clarity when multiplying a scalar by a hypervector.</p>
<p>This reservoir update forms product and cross-product terms from lagged values of the input. It retains the old terms across iterations and adds new terms at each iteration.</p>
<p>Note that this update probably can’t be used directly with self-inverse VSA schemes (e.g.&nbsp;BSC or MAP) because the multiplied terms would self-cancel. This update could be probably be used with self-inverse VSA schemes if the terms were permuted at each iteration.</p>
<p>To a first approximation the different scalar multipliers of the terms are irrelevant because all the terms will be multiplied by scalar coefficients in the regression readout. These readout coefficients can compensate for arbitrary scalar multipliers of the terms.</p>
<p>The scalar multipliers determine the relative magnitudes of the hypervectors corresponding to the algebraic terms. Given that the magnitude of the reservoir hypervector will almost certainly be normalised, this means that the terms with the smallest scalar multipliers will have the smallest smallest magnitudes. This raises the possibility that terms with very small magnitudes may become effectively invisible in the noise of the VSA system.</p>
<div style="page-break-after: always;"></div>
</section>
<section id="multiplicative-identity-mathbf1-and-copy-arcs" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="multiplicative-identity-mathbf1-and-copy-arcs"><span class="header-section-number">4.3</span> Multiplicative identity (<span class="math inline">\(\mathbf{1}\)</span>) and copy arcs</h2>
<p>The multiplicative identity (<span class="math inline">\(\mathbf{1}\)</span>) is in the update formula to copy terms across iterations. The update formula above generates a <span class="math inline">\(\mathbf{1}\)</span> term as an additive component of the reservoir hypervector at every iteration. This term is uninformative with respect to variation of the predictions. Given that some of the magnitude of the reservoir hypervector is used by the <span class="math inline">\(\mathbf{1}\)</span> term, that the magnitude of the reservoir hypervector is almost certainly normalised, and that the implementation will be noisy, the presence of the <span class="math inline">\(\mathbf{1}\)</span> term reduces the information capacity of the reservoir hypervector.</p>
<p>It would be interesting to see if a polynomial reservoir update can be constructed without using the multiplicative identity term (<span class="math inline">\(\mathbf{1}\)</span>). The key observation here is that binding with the multiplicative identity term is effectively a copy operation in the data VSA flow graph. Translate the reservoir update equation <span class="math inline">\(\mathbf{x}(n) = (\mathbf{x}(n-1) + \mathbf{1}) \times (\mathbf{u}(n) + \mathbf{1})\)</span> to a VSA data flow graph.</p>
<p>The circle nodes correspond to VSA operators: binary addition and multiplication, unary delay, and the multiplicative identity constant value. The arrows between nodes correspond to transfers of hypervectors. Some of the arrows are labelled with the corresponding terms in the update equation. The blue arrows correspond to the <span class="math inline">\((\mathbf{u}(n) + \mathbf{1})\)</span> term and the red arrows correspond to the <span class="math inline">\((\mathbf{x}(n-1) + \mathbf{1})\)</span> term, which will be simplified later.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<div>
<svg width="672" height="480" viewbox="0.00 0.00 160.29 260.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 256)">
<title>
Fig1
</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-256 156.29,-256 156.29,4 -4,4"></polygon> <!-- in --> <g id="node1" class="node">
<title>
in
</title>
<text text-anchor="middle" x="26.24" y="-229.8" font-family="Times,serif" font-size="14.00">in</text> </g> <!-- add1 --> <g id="node3" class="node">
<title>
add1
</title>
<ellipse fill="none" stroke="black" cx="39.24" cy="-162" rx="18" ry="18"></ellipse> <text text-anchor="middle" x="39.24" y="-157.8" font-family="Times,serif" font-size="14.00">+</text> </g> <!-- in&#45;&gt;add1 --> <g id="edge1" class="edge">
<title>
in-&gt;add1:nw
</title>
<path fill="none" stroke="lightblue" d="M23.32,-225.46C19.95,-215.6 15.47,-198.01 20.63,-184.73"></path> <polygon fill="lightblue" stroke="lightblue" points="23.78,-186.3 26.24,-176 17.89,-182.52 23.78,-186.3"></polygon> <text text-anchor="middle" x="11.66" y="-212.86" font-family="Times,serif" font-size="14.00">u(n)</text> </g> <!-- out --> <g id="node2" class="node">
<title>
out
</title>
<text text-anchor="middle" x="43.24" y="-13.8" font-family="Times,serif" font-size="14.00">out</text> </g> <!-- mul --> <g id="node5" class="node">
<title>
mul
</title>
<ellipse fill="none" stroke="black" cx="56.24" cy="-90" rx="18" ry="18"></ellipse> <text text-anchor="middle" x="56.24" y="-85.8" font-family="Times,serif" font-size="14.00">*</text> </g> <!-- add1&#45;&gt;mul --> <g id="edge4" class="edge">
<title>
add1:s-&gt;mul:nw
</title>
<path fill="none" stroke="lightblue" d="M39.24,-144C39.24,-130.32 34.18,-121.55 37.48,-112.51"></path> <polygon fill="lightblue" stroke="lightblue" points="40.54,-114.24 43.24,-104 34.74,-110.32 40.54,-114.24"></polygon> </g> <!-- add2 --> <g id="node4" class="node">
<title>
add2
</title>
<ellipse fill="none" stroke="black" cx="93.24" cy="-162" rx="18" ry="18"></ellipse> <text text-anchor="middle" x="93.24" y="-157.8" font-family="Times,serif" font-size="14.00">+</text> </g> <!-- add2&#45;&gt;mul --> <g id="edge5" class="edge">
<title>
add2:s-&gt;mul:ne
</title>
<path fill="none" stroke="red" d="M93.24,-144C93.24,-126.99 86.96,-120.84 76.61,-111.08"></path> <polygon fill="red" stroke="red" points="78.88,-108.41 69.24,-104 74.03,-113.45 78.88,-108.41"></polygon> </g> <!-- mul&#45;&gt;out --> <g id="edge6" class="edge">
<title>
mul:s-&gt;out
</title>
<path fill="none" stroke="lightgrey" d="M56.24,-72C56.24,-59.75 52.93,-46.36 49.65,-36.11"></path> <polygon fill="lightgrey" stroke="lightgrey" points="52.86,-34.69 46.26,-26.41 46.25,-37 52.86,-34.69"></polygon> <text text-anchor="middle" x="44.58" y="-59.4" font-family="Times,serif" font-size="14.00">x(n)</text> </g> <!-- del --> <g id="node6" class="node">
<title>
del
</title>
<ellipse fill="none" stroke="black" cx="88.24" cy="-18" rx="18" ry="18"></ellipse> <text text-anchor="middle" x="88.24" y="-13.8" font-family="Times,serif" font-size="14.00">delay</text> </g> <!-- mul&#45;&gt;del --> <g id="edge7" class="edge">
<title>
mul:s-&gt;del:w
</title>
<path fill="none" stroke="lightgrey" d="M56.24,-72C56.24,-67.52 59.85,-41.04 64.19,-26.9"></path> <polygon fill="lightgrey" stroke="lightgrey" points="67.35,-28.42 69.24,-18 61.26,-24.96 67.35,-28.42"></polygon> </g> <!-- del&#45;&gt;add2 --> <g id="edge8" class="edge">
<title>
del:e-&gt;add2:ne
</title>
<path fill="none" stroke="red" d="M107.24,-18C173.49,-18 158.05,-202.8 114.4,-182.05"></path> <polygon fill="red" stroke="red" points="116.36,-179.14 106.24,-176 112.19,-184.77 116.36,-179.14"></polygon> <text text-anchor="middle" x="124.74" y="-22.2" font-family="Times,serif" font-size="14.00">x(n-1)</text> </g> <!-- const1 --> <g id="node7" class="node">
<title>
const1
</title>
<ellipse fill="none" stroke="black" cx="73.24" cy="-234" rx="18" ry="18"></ellipse> <text text-anchor="middle" x="73.24" y="-229.8" font-family="Times,serif" font-size="14.00">1</text> </g> <!-- const1&#45;&gt;add1 --> <g id="edge2" class="edge">
<title>
const1:s-&gt;add1:ne
</title>
<path fill="none" stroke="lightblue" d="M73.24,-216C73.24,-199.69 68.75,-192.85 59.45,-183.24"></path> <polygon fill="lightblue" stroke="lightblue" points="61.78,-180.62 52.24,-176 56.82,-185.56 61.78,-180.62"></polygon> <text text-anchor="middle" x="69.74" y="-203.4" font-family="Times,serif" font-size="14.00">1</text> </g> <!-- const1&#45;&gt;add2 --> <g id="edge3" class="edge">
<title>
const1:s-&gt;add2:nw
</title>
<path fill="none" stroke="red" d="M73.24,-216C73.24,-202.04 69.8,-193.38 74.14,-184.27"></path> <polygon fill="red" stroke="red" points="77.12,-186.12 80.24,-176 71.49,-181.97 77.12,-186.12"></polygon> </g> </g>
</svg>
</div>
<figcaption class="figure-caption">Figure&nbsp;1: <span class="math inline">\(\mathbf{x}(n) = (\mathbf{x}(n-1) + \mathbf{1}) \times (\mathbf{u}(n) + \mathbf{1})\)</span></figcaption>
</figure>
</div>
</div>
</div>
<p>The purpose of the <span class="math inline">\(\mathbf{1}\)</span> in <span class="math inline">\((\mathbf{u}(n) + \mathbf{1})\)</span> is to copy <span class="math inline">\(\mathbf{x}(n-1)\)</span> into the result. This means that the updated result starts as a copy of the previous value of the result.</p>
<p>The purpose of the <span class="math inline">\(\mathbf{1}\)</span> in <span class="math inline">\((\mathbf{x}(n-1) + \mathbf{1})\)</span> is to copy <span class="math inline">\(\mathbf{u}(n)\)</span> into the result. This means that the current input is added in to the updated result.</p>
<p>The other term added into the result is <span class="math inline">\(\mathbf{x}(n-1) \times \mathbf{u}(n)\)</span>.</p>
<div style="page-break-after: always;"></div>
<p>In the next VSA data flow graph these three terms are calculated directly and added to form the result. This graph corresponds to the reservoir update equation: <span class="math inline">\(\mathbf{x}(n) = \mathbf{x}(n-1) + \mathbf{u}(n) + \mathbf{u}(n) \times \mathbf{x}(n-1)\)</span></p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<div>
<svg width="672" height="480" viewbox="0.00 0.00 135.41 223.80" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 219.8)">
<title>
Fig2
</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-219.8 131.41,-219.8 131.41,4 -4,4"></polygon> <!-- in --> <g id="node1" class="node">
<title>
in
</title>
<text text-anchor="middle" x="40.43" y="-203.2" font-family="Times,serif" font-size="14.00">in</text> </g> <!-- mul --> <g id="node3" class="node">
<title>
mul
</title>
<ellipse fill="none" stroke="black" cx="57.43" cy="-145" rx="18" ry="18"></ellipse> <text text-anchor="middle" x="57.43" y="-140.8" font-family="Times,serif" font-size="14.00">*</text> </g> <!-- in&#45;&gt;mul --> <g id="edge1" class="edge">
<title>
in:s-&gt;mul:ne
</title>
<path fill="none" stroke="#00ff00" d="M40.43,-199C40.43,-182.51 65.61,-177.12 72.17,-169.01"></path> <polygon fill="#00ff00" stroke="#00ff00" points="75.59,-168.25 70.43,-159 68.69,-169.45 75.59,-168.25"></polygon> </g> <!-- add --> <g id="node4" class="node">
<title>
add
</title>
<ellipse fill="none" stroke="black" cx="24.43" cy="-71.9" rx="18" ry="18"></ellipse> <text text-anchor="middle" x="24.43" y="-67.7" font-family="Times,serif" font-size="14.00">+</text> </g> <!-- in&#45;&gt;add --> <g id="edge2" class="edge">
<title>
in:s-&gt;add:nw
</title>
<path fill="none" stroke="lightblue" d="M40.43,-199C40.43,-150.96 -15.88,-126.38 4.88,-93.89"></path> <polygon fill="lightblue" stroke="lightblue" points="7.79,-95.85 11.43,-85.9 2.38,-91.41 7.79,-95.85"></polygon> <text text-anchor="middle" x="28.76" y="-186.4" font-family="Times,serif" font-size="14.00">u(n)</text> </g> <!-- out --> <g id="node2" class="node">
<title>
out
</title>
<text text-anchor="middle" x="24.43" y="-4.2" font-family="Times,serif" font-size="14.00">out</text> </g> <!-- mul&#45;&gt;add --> <g id="edge3" class="edge">
<title>
mul-&gt;add:n
</title>
<path fill="none" stroke="#00ff00" d="M44.76,-132.2C37.42,-124.31 29,-113.16 25.78,-100.91"></path> <polygon fill="#00ff00" stroke="#00ff00" points="29.23,-100.34 24.43,-90.9 22.3,-101.28 29.23,-100.34"></polygon> </g> <!-- add&#45;&gt;out --> <g id="edge4" class="edge">
<title>
add:s-&gt;out
</title>
<path fill="none" stroke="lightgrey" d="M24.43,-52.9C24.43,-44.38 24.43,-34.91 24.43,-26.99"></path> <polygon fill="lightgrey" stroke="lightgrey" points="27.93,-26.79 24.43,-16.79 20.93,-26.79 27.93,-26.79"></polygon> <text text-anchor="middle" x="12.76" y="-40.3" font-family="Times,serif" font-size="14.00">x(n)</text> </g> <!-- del --> <g id="node5" class="node">
<title>
del
</title>
<ellipse fill="none" stroke="black" cx="79.43" cy="-71.9" rx="19.2" ry="19.2"></ellipse> <text text-anchor="middle" x="79.43" y="-69.5" font-family="Times,serif" font-size="8.00">delay</text> </g> <!-- add&#45;&gt;del --> <g id="edge5" class="edge">
<title>
add:s-&gt;del:sw
</title>
<path fill="none" stroke="lightgrey" d="M24.43,-52.9C24.43,-37.53 43.6,-39.78 58.64,-50.88"></path> <polygon fill="lightgrey" stroke="lightgrey" points="56.66,-53.8 66.43,-57.9 61.34,-48.6 56.66,-53.8"></polygon> </g> <!-- del&#45;&gt;mul --> <g id="edge7" class="edge">
<title>
del:ne-&gt;mul:e
</title>
<path fill="none" stroke="#00ff00" d="M93.43,-86.9C109.85,-103.32 105.3,-134.69 86.44,-142.96"></path> <polygon fill="#00ff00" stroke="#00ff00" points="85.53,-139.57 76.43,-145 86.92,-146.43 85.53,-139.57"></polygon> </g> <!-- del&#45;&gt;add --> <g id="edge6" class="edge">
<title>
del:ne-&gt;add:ne
</title>
<path fill="none" stroke="red" d="M92.43,-85.9C107.79,-101.27 67.57,-104.74 44.34,-91.02"></path> <polygon fill="red" stroke="red" points="46.48,-88.24 36.43,-84.9 42.2,-93.78 46.48,-88.24"></polygon> <text text-anchor="middle" x="109.92" y="-90.1" font-family="Times,serif" font-size="14.00">x(n-1)</text> </g> </g>
</svg>
</div>
<figcaption class="figure-caption">Figure&nbsp;2: <span class="math inline">\(\mathbf{x}(n) = \mathbf{x}(n-1) + \mathbf{u}(n) + \mathbf{u}(n) \times \mathbf{x}(n-1)\)</span></figcaption>
</figure>
</div>
</div>
</div>
<p>Trace out the repeated application of the reservoir update equation, starting from time <span class="math inline">\(n = 0\)</span> with an empty reservoir, <span class="math inline">\(\mathbf{x}(0) = \mathbf{0}\)</span>.</p>
<p><span class="math display">\[\mathbf{x}(n) = \mathbf{x}(n-1) + \mathbf{u}(n) + \mathbf{u}(n) \times \mathbf{x}(n-1)\]</span></p>
<p><span class="math inline">\(\mathbf{x}(0) = \mathbf{0}\)</span><br>
<br>
<span class="math inline">\(\mathbf{x}(1) = \mathbf{x}(0) + \mathbf{u}(1) + \mathbf{u}(1) \times \mathbf{x}(0)\)</span><br>
<span class="math inline">\(= \mathbf{0} + \mathbf{u}(1) + \mathbf{0}\)</span><br>
<span class="math inline">\(= \mathbf{u}(1)\)</span><br>
<br>
<span class="math inline">\(\mathbf{x}(2) = \mathbf{x}(1) + \mathbf{u}(2) + \mathbf{u}(2) \times \mathbf{x}(1)\)</span><br>
<span class="math inline">\(= \mathbf{u}(1) + \mathbf{u}(2) + \mathbf{u}(2) \times \mathbf{u}(1)\)</span><br>
<br>
<span class="math inline">\(\mathbf{x}(3) = \mathbf{x}(2) + \mathbf{u}(3) + \mathbf{u}(3) \times \mathbf{x}(2)\)</span><br>
<span class="math inline">\(= (\mathbf{u}(1) + \mathbf{u}(2) + \mathbf{u}(2) \times \mathbf{u}(1)) + \mathbf{u}(3) + \mathbf{u}(3) \times (\mathbf{u}(1) + \mathbf{u}(2) + \mathbf{u}(2) \times \mathbf{u}(1))\)</span><br>
<span class="math inline">\(= \mathbf{u}(1) + \mathbf{u}(2) + \mathbf{u}(2) \times \mathbf{u}(1) + \mathbf{u}(3) + \mathbf{u}(3) \times \mathbf{u}(1) + \mathbf{u}(3) \times \mathbf{u}(2) + \mathbf{u}(3) \times \mathbf{u}(2) \times \mathbf{u}(1)\)</span></p>
<p>This generates all the interactions of increasing order.</p>
<div style="page-break-after: always;"></div>
</section>
<section id="reservoir-update-with-permutation" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="reservoir-update-with-permutation"><span class="header-section-number">4.4</span> Reservoir update with permutation</h2>
<p>I noted earlier that permutation would be required if we tried to use a self-inverse VSA scheme with this kind of reservoir update that generates products of terms. Note that the interaction terms generated above are unordered because of the commutativity of the product operator. If we used a noncommutative product then we wouldn’t need to use permutation to capture the the ordering of the terms.</p>
<p>An interesting case occurs when we use Fractional Power Encoded scalar values as inputs. FPE encoded values are equivalent to vectors and the product of FPE encoded values is equivalent to vector addition of the component vectors. The result is the same regardless of the order in which the vectors are added. If the order of the vector values is important for the problem being solved by the reservoir computer (e.g.&nbsp;in navigation where the path to the destination is important, rather than the location of the destination) then we need to encode the vectors in a way that is sensitive to the order, for example by applying permutation powers to the vectors.</p>
<p>There is probably no single “right” way to construct a reservoir update and we will need to design it to meet the requirements of the current task. Let’s do that here. We’ll take the previous reservoir update equation and modify it to meet some (ambiguous and ill-defined) objectives.</p>
<p>We will assume that the input stream is FPE-encoded vectors and that the sequence of vectors is a reasonable predictor of the outcome. We will also assume that polynomial terms of the predictors are important predictors.</p>
<p>The previous update equation created output terms that were direct copies of prior input terms. This is effectively claiming that input values are good predictors regardless of when they occurred in the past. Let’s assume that is likely to be incorrect, so we need to modify the update equation to prevent the repeated direct copying of inputs across generations. We attempt to do this by deleting the arrow between the delay node and the addition node.</p>
<p>We believe the successor relation is predictive, so need to bind successor states and apply the “before” permutation <span class="math inline">\(P_{bef}\)</span> to the representation of the earlier state. We do this by inserting the permutation node <span class="math inline">\(P_{bef}\)</span> into the arrow between the delay node and the product node.</p>
<p>This graph corresponds to the reservoir update equation: <span class="math inline">\(\mathbf{x}(n) = \mathbf{u}(n) + \mathbf{u}(n) \times \textrm{P}_{bef}(\mathbf{x}(n-1))\)</span><br>
That is, the current state consists of the current input plus the encoded sequence of states leading to the current state.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<div>
<svg width="672" height="480" viewbox="0.00 0.00 156.31 223.80" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 219.8)">
<title>
Fig3
</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-219.8 152.31,-219.8 152.31,4 -4,4"></polygon> <!-- in --> <g id="node1" class="node">
<title>
in
</title>
<text text-anchor="middle" x="23.32" y="-203.2" font-family="Times,serif" font-size="14.00">in</text> </g> <!-- mul --> <g id="node3" class="node">
<title>
mul
</title>
<ellipse fill="none" stroke="black" cx="46.32" cy="-145" rx="18" ry="18"></ellipse> <text text-anchor="middle" x="46.32" y="-140.8" font-family="Times,serif" font-size="14.00">*</text> </g> <!-- in&#45;&gt;mul --> <g id="edge1" class="edge">
<title>
in:s-&gt;mul:n
</title>
<path fill="none" stroke="lightgrey" d="M23.32,-199C23.32,-184.17 37.36,-182.13 43.5,-172.89"></path> <polygon fill="lightgrey" stroke="lightgrey" points="46.95,-173.58 46.32,-163 40.22,-171.66 46.95,-173.58"></polygon> </g> <!-- add --> <g id="node4" class="node">
<title>
add
</title>
<ellipse fill="none" stroke="black" cx="44.32" cy="-71.9" rx="18" ry="18"></ellipse> <text text-anchor="middle" x="44.32" y="-67.7" font-family="Times,serif" font-size="14.00">+</text> </g> <!-- in&#45;&gt;add --> <g id="edge2" class="edge">
<title>
in:s-&gt;add:nw
</title>
<path fill="none" stroke="lightgrey" d="M23.32,-199C23.32,-152.35 -0.36,-125.68 24.4,-93.71"></path> <polygon fill="lightgrey" stroke="lightgrey" points="27.31,-95.7 31.32,-85.9 22.07,-91.06 27.31,-95.7"></polygon> <text text-anchor="middle" x="11.66" y="-186.4" font-family="Times,serif" font-size="14.00">u(n)</text> </g> <!-- out --> <g id="node2" class="node">
<title>
out
</title>
<text text-anchor="middle" x="44.32" y="-4.2" font-family="Times,serif" font-size="14.00">out</text> </g> <!-- mul&#45;&gt;add --> <g id="edge3" class="edge">
<title>
mul-&gt;add:n
</title>
<path fill="none" stroke="lightgrey" d="M45.35,-126.79C44.98,-119.24 44.61,-110.05 44.43,-100.98"></path> <polygon fill="lightgrey" stroke="lightgrey" points="47.93,-100.86 44.32,-90.9 40.93,-100.94 47.93,-100.86"></polygon> </g> <!-- add&#45;&gt;out --> <g id="edge4" class="edge">
<title>
add:s-&gt;out
</title>
<path fill="none" stroke="lightgrey" d="M44.32,-52.9C44.32,-44.38 44.32,-34.91 44.32,-26.99"></path> <polygon fill="lightgrey" stroke="lightgrey" points="47.82,-26.79 44.32,-16.79 40.82,-26.79 47.82,-26.79"></polygon> <text text-anchor="middle" x="32.66" y="-40.3" font-family="Times,serif" font-size="14.00">x(n)</text> </g> <!-- del --> <g id="node6" class="node">
<title>
del
</title>
<ellipse fill="none" stroke="black" cx="99.32" cy="-71.9" rx="19.2" ry="19.2"></ellipse> <text text-anchor="middle" x="99.32" y="-69.5" font-family="Times,serif" font-size="8.00">delay</text> </g> <!-- add&#45;&gt;del --> <g id="edge5" class="edge">
<title>
add:s-&gt;del:sw
</title>
<path fill="none" stroke="lightgrey" d="M44.32,-52.9C44.32,-37.53 63.5,-39.78 78.54,-50.88"></path> <polygon fill="lightgrey" stroke="lightgrey" points="76.55,-53.8 86.32,-57.9 81.24,-48.6 76.55,-53.8"></polygon> </g> <!-- pbef --> <g id="node5" class="node">
<title>
pbef
</title>
<ellipse fill="none" stroke="black" cx="100.32" cy="-145" rx="18" ry="18"></ellipse> <text text-anchor="middle" x="100.32" y="-142.6" font-family="Times,serif" font-size="8.00">Pbef</text> </g> <!-- pbef&#45;&gt;mul --> <g id="edge7" class="edge">
<title>
pbef:nw-&gt;mul:ne
</title>
<path fill="none" stroke="lightgrey" d="M86.32,-158C75.46,-168.87 69.7,-169.56 64.83,-165.66"></path> <polygon fill="lightgrey" stroke="lightgrey" points="67.47,-163.36 58.32,-158 62.13,-167.89 67.47,-163.36"></polygon> </g> <!-- del&#45;&gt;pbef --> <g id="edge6" class="edge">
<title>
del:ne-&gt;pbef:se
</title>
<path fill="none" stroke="lightgrey" d="M113.32,-86.9C124.58,-98.16 126.7,-111.09 119.66,-122.97"></path> <polygon fill="lightgrey" stroke="lightgrey" points="116.77,-120.98 113.32,-131 122.27,-125.32 116.77,-120.98"></polygon> <text text-anchor="middle" x="130.82" y="-91.1" font-family="Times,serif" font-size="14.00">x(n-1)</text> </g> </g>
</svg>
</div>
<figcaption class="figure-caption">Figure&nbsp;3: <span class="math inline">\(\mathbf{x}(n) = \mathbf{u}(n) + \mathbf{u}(n) \times \textrm{P}_{bef}(\mathbf{x}(n-1))\)</span></figcaption>
</figure>
</div>
</div>
</div>
<p>Trace out the repeated application of the reservoir update equation, starting from time <span class="math inline">\(n = 0\)</span> with an empty reservoir, <span class="math inline">\(\mathbf{x}(0) = \mathbf{0}\)</span>.</p>
<p><span class="math inline">\(\mathbf{x}(n) = \mathbf{u}(n) + \mathbf{u}(n) \times \textrm{P}_{bef}(\mathbf{x}(n-1))\)</span></p>
<p><span class="math inline">\(\mathbf{x}(0) = \mathbf{0}\)</span><br>
<br>
<span class="math inline">\(\mathbf{x}(1) = \mathbf{u}(1) + \mathbf{u}(1) \times \textrm{P}_{bef}(\mathbf{x}(0))\)</span><br>
<span class="math inline">\(= \mathbf{u}(1) + \mathbf{u}(1) \times \textrm{P}_{bef}(\mathbf{0})\)</span><br>
<span class="math inline">\(= \mathbf{u}(1) + \mathbf{u}(1) \times \mathbf{0}\)</span><br>
<span class="math inline">\(= \mathbf{u}(1) + \mathbf{0}\)</span><br>
<span class="math inline">\(= \mathbf{u}(1)\)</span><br>
<br>
<span class="math inline">\(\mathbf{x}(2) = \mathbf{u}(2) + \mathbf{u}(2) \times \textrm{P}_{bef}(\mathbf{x}(1))\)</span><br>
<span class="math inline">\(= \mathbf{u}(2) + \mathbf{u}(2) \times \textrm{P}_{bef}(\mathbf{u}(1))\)</span><br>
<br>
<span class="math inline">\(\mathbf{x}(3) = \mathbf{u}(3) + \mathbf{u}(3) \times \textrm{P}_{bef}(\mathbf{x}(2))\)</span><br>
<span class="math inline">\(= \mathbf{u}(3) + \mathbf{u}(3) \times \textrm{P}_{bef}(\mathbf{u}(2) + \mathbf{u}(2) \times \textrm{P}_{bef}(\mathbf{u}(1)))\)</span><br>
<span class="math inline">\(= \mathbf{u}(3) + \mathbf{u}(3) \times (\textrm{P}_{bef}(\mathbf{u}(2)) + \textrm{P}_{bef}(\mathbf{u}(2)) \times \textrm{P}^2_{bef}(\mathbf{u}(1)))\)</span><br>
<span class="math inline">\(= \mathbf{u}(3) + \mathbf{u}(3) \times \textrm{P}_{bef}(\mathbf{u}(2)) + \mathbf{u}(3) \times \textrm{P}_{bef}(\mathbf{u}(2)) \times \textrm{P}^2_{bef}(\mathbf{u}(1))\)</span><br>
</p>
<p>This reservoir generates all the sequences of input values of increasing length.</p>
<p>Obviously there is plenty of scope for modifying the update equation to generate different predictors.</p>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="feature-fading" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Feature fading</h1>
<p>In general every iteration through the reservoir update equation can add more terms to the reservoir state. This can continue arbitrarily long, so the reservoir state can become arbitrarily complex (when viewed as algebraic terms).</p>
<p>You might think this would cause problems because the number of features keeps increasing and because it implies infinite memory (terms hanging around forever). In practice this is not an issue because the magnitudes of the terms decrease over time because of the bundling update. Eventually the terms will have such a low magnitude that they are effectively lost in the system noise.</p>
<section id="nonassociative-bundling" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="nonassociative-bundling"><span class="header-section-number">5.1</span> Nonassociative bundling</h2>
<p>Bundling (as implemented, rather than as a mathematical abstraction) loses information. The more times a term has passed through bundling, the more information it has lost. This is reflected in the reducing magnitude of the hypervector representing the algebraic term.</p>
<p>This is most obvious when you consider randsel bundling <span class="citation" data-cites="gaylerImplementRandselBundling2022 heddesRandselTorchhdDocumentation2022">(<a href="#ref-gaylerImplementRandselBundling2022" role="doc-biblioref">Gayler 2022</a>; <a href="#ref-heddesRandselTorchhdDocumentation2022" role="doc-biblioref">Heddes et al. 2022</a>)</span>. In randsel bundling each output element is selected at random from the corresponding elements of the argument hypervectors. With two arguments and equal selection probability only half the elements are copied from each argument hypervector to the result hypervector. Consequently, the hypervector representing each algebraic term has half it’s original magnitude. Thus, the half-life of each term in the reservoir would be one time step.</p>
</section>
<section id="weighted-bundling" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="weighted-bundling"><span class="header-section-number">5.2</span> Weighted bundling</h2>
<p>Note that the bundling operator doesn’t have to be binary, it can have an arbitrary (but generally small) number of arguments. We can also associate a positive scalar weight with each argument that controls the relative contribution of that argument to the result.</p>
<p>For example in <a href="#fig-2">Figure&nbsp;2</a>, the bundling operator has three arguments. This could be implemented as weighted bundling and the weights used to control the relative magnitudes of the arguments in the result. Increasing the weight of the <span class="math inline">\(\mathbf{x}(n-1)\)</span> term would increase the magnitude of the current reservoir state preserved in the next state and therefore extend the retention duration of the reservoir (at the cost of decreasing the relative magnitudes of the <span class="math inline">\(\mathbf{u}(n)\)</span> and <span class="math inline">\((\mathbf{u}(n) \times \mathbf{x}(n-1))\)</span> added in at each time step).</p>
</section>
<section id="bundled-inputs" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="bundled-inputs"><span class="header-section-number">5.3</span> Bundled inputs</h2>
<p>The preceding discussions might have given the impression that the input stream (<span class="math inline">\(\mathbf{u}(n)\)</span>) consists of atomic vectors. However, the joy of VSA is that everything is just a hypervector value, so the input stream could be arbitrarily complicated values. In particular the input stream could consist of the sum of the input and output streams used in classical RC, and weighted bundling could be used to control their relative contributions.</p>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="development-suggestions" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Development suggestions</h1>
<p>The following points are directions that might be worth investigating.</p>
<section id="inputhierarchical-encoding" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="inputhierarchical-encoding"><span class="header-section-number">6.1</span> Input/hierarchical encoding</h2>
<p>It might be advantageous to construct sequence representations in the input streams rather than in the reservoir update. This might be equivalent to hierarchical reservoirs. We could have input-stream-specific reservoirs that create input sequence representations and a stream fusion reservoir (or maybe stream fusion doesn’t need the recurrent update).</p>
</section>
<section id="intercept-term" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="intercept-term"><span class="header-section-number">6.2</span> Intercept term</h2>
<p>Reservoir readout is performed by a weighted sum (effectively a regression model). Statistical regression normally allows for an intercept (bias) term and the goodness of fit can depend strongly on whether an intercept term is included in the readout model.</p>
<p>Typical statistical regression software normally constructs the intercept term implicitly rather than requiring it to be explicitly present as a predictor. Depending on how the readout has been implemented in some VSA RC model it is possible that the intercept term has not been included.</p>
<ul>
<li><p>For any specific VSA RC implementation, check on how the intercept term is treated in the reservoir readout (both in training and prediction).</p></li>
<li><p>If readout is performed by standard regression (including ridge regression) it can be implemented by concatenating a single constant 1 element to the RC reservoir hypervector.</p></li>
<li><p>If readout is implemented by VSA bundling it is only necessary to ensure that the reservoir hypervector contains a multiplicative identity hypervector term (<span class="math inline">\(\mathbf{1}\)</span>).</p></li>
</ul>
</section>
<section id="bundling-and-capacity" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="bundling-and-capacity"><span class="header-section-number">6.3</span> Bundling and capacity</h2>
<p>The discussion of feature fading and weighted bundling shows that we need a better treatment of bundling and capacity than just considering the number of items that are included in the bundle. It’s not just the number of superposed items, which can be changed arbitrarily by algebraic re-arrangement. Also, a <span class="math inline">\(d\)</span>-dimensional HRR binding is equivalent to the sum of <span class="math inline">\(d\)</span> many MAP bindings, but only counts as one item in the traditional capacity analysis.</p>
</section>
<section id="warm-up" class="level2" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="warm-up"><span class="header-section-number">6.4</span> Warm up</h2>
<p>Standard RC uses a warm-up to allow the reservoir state to get past any transient states arising from the initial value of the reservoir.</p>
<ul>
<li><p>Investigate the impact of initial values on the length of required warm-up. In the formulae above I used zero hypervector initial values. Other possibilities are the one hypervector and a randomly selected hypervector. Another reasonable choice might be to randomly select a value from the set of reservoir values seen after warm-up. I would be interesting to investigate how long it takes the reservoir to synchronise to the new input.</p></li>
<li><p>Investigate whether it is possible to read-out from the reservoir during the warm-up phase. A realistic environment is non-stationary, so arguably there is a continual stream of (partial?) re-starts. There would be an evolutionary advantage to the readout being useful, regardless of how recently the system had been restarted.</p></li>
</ul>
</section>
<section id="dynamic-readout" class="level2" data-number="6.5">
<h2 data-number="6.5" class="anchored" data-anchor-id="dynamic-readout"><span class="header-section-number">6.5</span> Dynamic readout</h2>
<p>Rather than having a fixed-weight readout mechanism, is it possible to have a readout mechanism that varies in response to the task demands at readout time? This might be related to avoidance of catastrophic forgetting (e.g. <span class="citation" data-cites="frenchDynamicallyConstrainingConnectionist1994">French (<a href="#ref-frenchDynamicallyConstrainingConnectionist1994" role="doc-biblioref">1994</a>)</span>) and generalisation at recall rather than in a separate training phase (e.g. <span class="citation" data-cites="shabahangGeneralizationRetrievalUsing2022">Shabahang, Yim, and Dennis (<a href="#ref-shabahangGeneralizationRetrievalUsing2022" role="doc-biblioref">2022</a>)</span>).</p>
</section>
<section id="dynamic-update" class="level2" data-number="6.6">
<h2 data-number="6.6" class="anchored" data-anchor-id="dynamic-update"><span class="header-section-number">6.6</span> Dynamic update</h2>
<p>Continuing the same theme of making RC mechanisms dynamic, it might be possible for the update formula to change dynamically to indefinitely preserve the contents of the reservoir as a working memory and to emphasize representational components that are most relevant to the current task. For example, it might be appropriate to insert a dynamically updated cleanup memory in the reservoir update loop.</p>
<p>Another point to consider is whether to include gating in the reservoir update loop, so that the reservoir is only updated when there are material changes in the environment rather than every time step.</p>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="references" class="level1 unnumbered" data-number="7">


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">7 References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-fradyTheorySequenceIndexing2018a" class="csl-entry" role="listitem">
Frady, E. Paxon, Denis Kleyko, and Friedrich T. Sommer. 2018. <span>“A Theory of Sequence Indexing and Working Memory in Recurrent Neural Networks.”</span> <em>Neural Computation</em> 30 (6): 1449–1513. <a href="https://doi.org/10.1162/neco_a_01084">https://doi.org/10.1162/neco_a_01084</a>.
</div>
<div id="ref-frenchDynamicallyConstrainingConnectionist1994" class="csl-entry" role="listitem">
French, Robert M. 1994. <span>“Dynamically Constraining Connectionist Networks to Produce Distributed, Orthogonal Representations to Reduce Catastrophic Interference.”</span> In <em>Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society</em>, edited by Ashwin Ram and Kurt Eiselt, 335–40. Atlanta, GA, USA: Routledge. <a href="https://doi.org/10.4324/9781315789354-58">https://doi.org/10.4324/9781315789354-58</a>.
</div>
<div id="ref-gauthierNextGenerationReservoir2021" class="csl-entry" role="listitem">
Gauthier, Daniel J., Erik Bollt, Aaron Griffith, and Wendson A. S. Barbosa. 2021. <span>“Next Generation Reservoir Computing.”</span> <em>Nature Communications</em> 12 (1): 5564. <a href="https://doi.org/10.1038/s41467-021-25801-2">https://doi.org/10.1038/s41467-021-25801-2</a>.
</div>
<div id="ref-gaylerImplementRandselBundling2022" class="csl-entry" role="listitem">
Gayler, Ross W. 2022. <span>“Implement Randsel Bundling · Issue #75 · Hyperdimensional-Computing/Torchhd.”</span> GitHub repository. GitHub. June 4, 2022. <a href="https://github.com/hyperdimensional-computing/torchhd/issues/75">https://github.com/hyperdimensional-computing/torchhd/issues/75</a>.
</div>
<div id="ref-heddesRandselTorchhdDocumentation2022" class="csl-entry" role="listitem">
Heddes, Mike, Igor Nunes, Dheyay Desai, and Pere Vergés. 2022. <span>“Randsel — Torchhd Documentation.”</span> Torchhd Documentation. 2022. <a href="https://torchhd.readthedocs.io/en/stable/generated/torchhd.randsel.html">https://torchhd.readthedocs.io/en/stable/generated/torchhd.randsel.html</a>.
</div>
<div id="ref-kanervaFullyDistributedRepresentation1997" class="csl-entry" role="listitem">
Kanerva, Pentti. 1997. <span>“Fully Distributed Representation.”</span> In, 358–65.
</div>
<div id="ref-kleykoIntegerEchoState2022" class="csl-entry" role="listitem">
Kleyko, Denis, Edward Paxon Frady, Mansour Kheffache, and Evgeny Osipov. 2022. <span>“Integer Echo State Networks: Efficient Reservoir Computing for Digital Hardware.”</span> <em>IEEE Transactions on Neural Networks and Learning Systems</em> 33 (4): 1688–1701. <a href="https://doi.org/10.1109/TNNLS.2020.3043309">https://doi.org/10.1109/TNNLS.2020.3043309</a>.
</div>
<div id="ref-kleykoSurveyHyperdimensionalComputing2022a" class="csl-entry" role="listitem">
Kleyko, Denis, Dmitri A. Rachkovskij, Evgeny Osipov, and Abbas Rahimi. 2022. <span>“A Survey on Hyperdimensional Computing Aka Vector Symbolic Architectures, Part I: Models and Data Transformations.”</span> <em>ACM Computing Surveys</em>, May, 3538531. <a href="https://doi.org/10.1145/3538531">https://doi.org/10.1145/3538531</a>.
</div>
<div id="ref-qiuGraphEmbeddingsTensor2022" class="csl-entry" role="listitem">
Qiu, Frank. n.d. <span>“Graph Embeddings via Tensor Products and Approximately Orthonormal Codes.”</span> <a href="http://arxiv.org/abs/2208.10917">http://arxiv.org/abs/2208.10917</a>.
</div>
<div id="ref-shabahangGeneralizationRetrievalUsing2022" class="csl-entry" role="listitem">
Shabahang, Kevin D., Hyungwook Yim, and Simon J. Dennis. 2022. <span>“Generalization at Retrieval Using Associative Networks with Transient Weight Changes.”</span> <em>Computational Brain &amp; Behavior</em> 5 (1): 124–55. <a href="https://doi.org/10.1007/s42113-022-00127-4">https://doi.org/10.1007/s42113-022-00127-4</a>.
</div>
</div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>